{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c156d8-34dc-47e9-b12f-153f3a2a5d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "#DATA PREPROCESSING\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import umap\n",
    "import hdbscan\n",
    "import gc\n",
    "import torch\n",
    "from transformers import LEDTokenizer, LEDModel\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Global config\n",
    "PATH_X1 = \"/Users/jingyi/Desktop/Trauma_LLM/all_patient/data_Hsp12.feather\"\n",
    "PATH_X2 = \"/Users/jingyi/Desktop/Trauma_LLM/all_patient/indvd_metric.csv\"\n",
    "PATH_X3 = \"/Users/jingyi/Desktop/Trauma_LLM/all_patient/indvd_metric_raw.csv\"\n",
    "PATH_METRIC_DEF = \"/Users/jingyi/Desktop/Trauma_LLM/metric_def.xlsx\"\n",
    "\n",
    "EMB_MODEL_NAME = \"allenai/led-base-16384\"\n",
    "MAX_TOKENS = 16000\n",
    "N_COMPONENTS_CLUST = 10   # dimension need to be changed\n",
    "N_NEIGHBORS = 15\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ccaefa-3819-4259-b046-135d37ffc84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in X2:\n",
      "['QI']\n",
      "\n",
      "Columns only in X3:\n",
      "['mtrc102', 'mtrc106', 'mtrc14', 'mtrc166', 'mtrc168', 'mtrc233', 'mtrc242', 'mtrc242001', 'mtrc25', 'mtrc29', 'mtrc80', 'mtrc85', 'mtrc96', 'mtrcNA']\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "X2 = pd.read_csv(PATH_X2)\n",
    "X3 = pd.read_csv(PATH_X3)\n",
    "\n",
    "# Compare column names\n",
    "x2_cols = set(X2.columns)\n",
    "x3_cols = set(X3.columns)\n",
    "\n",
    "only_in_X2 = sorted(x2_cols - x3_cols)\n",
    "only_in_X3 = sorted(x3_cols - x2_cols)\n",
    "common_cols = sorted(x2_cols & x3_cols)\n",
    "\n",
    "print(\"Columns only in X2:\")\n",
    "print(only_in_X2 if only_in_X2 else \"None\")\n",
    "\n",
    "print(\"\\nColumns only in X3:\")\n",
    "print(only_in_X3 if only_in_X3 else \"None\")\n",
    "\n",
    "#print(\"\\nCommon columns:\")\n",
    "#print(common_cols if common_cols else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51857cf-2686-434f-8135-a139c15d14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_only_in_x3 = [\n",
    "    \"mtrc102\", \"mtrc106\", \"mtrc14\", \"mtrc166\", \"mtrc168\", \"mtrc233\",\n",
    "    \"mtrc242\", \"mtrc242001\", \"mtrc25\", \"mtrc29\", \"mtrc80\", \"mtrc85\",\n",
    "    \"mtrc96\", \"mtrcNA\"\n",
    "]\n",
    "\n",
    "X3 = X3.drop(columns=cols_only_in_x3, errors=\"ignore\")\n",
    "X2 = X3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467deee9-acb9-4acd-a48e-901b64d0bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X1 shape: (103362, 1571)\n",
      "X1 shape after dropping cols: (103362, 1278)\n",
      "Aligned X2 shape: (103362, 116)\n",
      "X4 shape: (103362, 1393)\n"
     ]
    }
   ],
   "source": [
    "X1 = pd.read_feather(PATH_X1)\n",
    "print(\"Original X1 shape:\", X1.shape)\n",
    "\n",
    "cols_to_drop = [\n",
    "    'mpp_121', 'mpp_125', 'mpp_16', 'mpp_168', 'mpp_236', 'mpp_242', 'mpp_71',\n",
    "    'proc_01_icd', 'proc_02_icd', 'proc_03_icd', 'proc_04_icd', 'proc_05_icd',\n",
    "    'proc_06_icd', 'proc_07_icd', 'proc_08_icd', 'proc_09_icd', 'proc_10_icd',\n",
    "    'proc_11_icd', 'proc_12_icd', 'proc_13_icd', 'proc_14_icd', 'proc_15_icd',\n",
    "    'proc_16_icd', 'proc_17_icd', 'proc_18_icd', 'proc_19_icd', 'proc_20_icd',\n",
    "    'proc_21_icd', 'proc_22_icd', 'proc_23_icd', 'proc_24_icd', 'proc_25_icd',\n",
    "    'proc_26_icd', 'proc_27_icd', 'proc_28_icd', 'proc_29_icd', 'proc_30_icd',\n",
    "    'proc_31_icd', 'proc_32_icd', 'proc_33_icd', 'proc_34_icd', 'proc_35_icd',\n",
    "    'proc_36_icd', 'proc_37_icd', 'proc_38_icd', 'proc_39_icd', 'proc_40_icd',\n",
    "    'proc_41_icd', 'proc_42_icd', 'proc_43_icd', 'proc_44_icd', 'proc_45_icd',\n",
    "    'proc_46_icd', 'proc_47_icd', 'proc_48_icd', 'proc_49_icd', 'proc_50_icd',\n",
    "    'proc_51_icd', 'proc_52_icd', 'proc_53_icd', 'proc_54_icd', 'proc_55_icd',\n",
    "    'proc_56_icd', 'proc_57_icd', 'proc_58_icd', 'proc_59_icd', 'proc_60_icd',\n",
    "    'proc_61_icd', 'proc_62_icd', 'proc_63_icd', 'proc_64_icd', 'proc_65_icd',\n",
    "    'proc_66_icd', 'proc_67_icd', 'proc_68_icd', 'proc_69_icd', 'proc_70_icd',\n",
    "    'proc_71_icd', 'proc_72_icd', 'proc_73_icd', 'proc_74_icd', 'proc_75_icd',\n",
    "    'proc_76_icd', 'proc_77_icd', 'proc_78_icd', 'proc_79_icd', 'proc_80_icd',\n",
    "    'proc_81_icd', 'proc_82_icd', 'proc_83_icd', 'proc_84_icd', 'fac_key', 'disp_tx', 'scene_tx', 'leave_tx',\n",
    "    'gcs40eye_s',  'gcs40ver_s', 'gcs40mot_s',  'gcs40eye_r', 'gcs40ver_r','gcs40mot_r'\n",
    "]\n",
    "cols_to_drop += [f\"ais_sev_{i:02d}\" for i in range(1, 28)]\n",
    "cols_to_drop += [f\"icd9_{i:02d}\" for i in range(1, 28)]\n",
    "\n",
    "# predot_01 ... predot_27\n",
    "cols_to_drop += [f\"predot_{i:02d}\" for i in range(1, 28)]\n",
    "\n",
    "# proc_01 ... proc_84\n",
    "cols_to_drop += [f\"proc_{i:02d}\" for i in range(1, 85)]\n",
    "\n",
    "# ais_01 ... ais_27\n",
    "cols_to_drop += [f\"ais_{i:02d}\" for i in range(1, 28)]\n",
    "\n",
    "X1 = X1.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "print(\"X1 shape after dropping cols:\", X1.shape)\n",
    "\n",
    "# 1b. Read X2 csv\n",
    "#X2 = pd.read_csv(PATH_X2)\n",
    "#X2 = X2.drop(columns=\"QI\", errors=\"ignore\")\n",
    "# Align X2 rows so that inc_key order matches X1\n",
    "if \"inc_key\" not in X1.columns or \"inc_key\" not in X2.columns:\n",
    "    raise ValueError(\"Both X1 and X2 must contain 'inc_key' column.\")\n",
    "\n",
    "X2 = X2.set_index(\"inc_key\").reindex(X1[\"inc_key\"]).reset_index()\n",
    "print(\"Aligned X2 shape:\", X2.shape)\n",
    "\n",
    "# Assumes X1 and X2 are already loaded and aligned as in your existing code.\n",
    "X2_features_only = X2.drop(columns=[\"inc_key\"])\n",
    "X4 = pd.concat([X1, X2_features_only], axis=1)\n",
    "print(\"X4 shape:\", X4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44f811b-9bfc-4c78-82ad-75c23c365fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes:\n",
      "(103362, 768) (103362, 1)\n",
      "(103362, 768) (103362, 1)\n",
      "\n",
      "Normalizing embeddings...\n",
      "Normalization complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Load your data (Your existing code)\n",
    "X1_emb = np.load(\"/Users/jingyi/Desktop/Trauma_LLM/all_patient/originaldata_LED_emb_103362.npy\")\n",
    "X2_emb = np.load(\"/Users/jingyi/Desktop/Trauma_LLM/all_patient/indvdmetric_LED_emb.npy\")\n",
    "\n",
    "X1_inc_key = pd.read_csv(\"/Users/jingyi/Desktop/Trauma_LLM/all_patient/originaldata_inc_key.csv\")\n",
    "X2_inc_key = pd.read_csv(\"/Users/jingyi/Desktop/Trauma_LLM/all_patient/indvdmetric_inc_key.csv\")\n",
    "\n",
    "print(\"Original shapes:\")\n",
    "print(X1_emb.shape, X1_inc_key.shape)\n",
    "print(X2_emb.shape, X2_inc_key.shape)\n",
    "\n",
    "# --- NORMALIZATION STEP ---\n",
    "\n",
    "# L2 Normalization maps all vectors to the unit sphere\n",
    "# This makes Euclidean distance equivalent to Cosine distance\n",
    "print(\"\\nNormalizing embeddings...\")\n",
    "X1_emb = normalize(X1_emb, norm='l2')\n",
    "X2_emb = normalize(X2_emb, norm='l2')\n",
    "\n",
    "print(\"Normalization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f2d1f3-f4d9-4848-a54c-b04688cf2662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X1_umap_d shape: (103362, 10)\n",
      "Loaded X1_labels shape: (103362,)\n",
      "Unique clusters (excluding -1): {np.int32(0), np.int32(1), np.int32(2), np.int32(3), np.int32(4), np.int32(5), np.int32(6), np.int32(7)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"X1_umap_hdbscan_outputs.npz\")\n",
    "\n",
    "X1_umap_d = data[\"X1_umap_d\"]\n",
    "X1_labels = data[\"X1_labels\"]\n",
    "\n",
    "print(\"Loaded X1_umap_d shape:\", X1_umap_d.shape)\n",
    "print(\"Loaded X1_labels shape:\", X1_labels.shape)\n",
    "print(\"Unique clusters (excluding -1):\", set(X1_labels) - {-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39226ba9-f15b-4a2a-8d8f-3843fb9d51b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X4_umap_d shape: (103362, 10)\n",
      "Loaded X4_labels shape: (103362,)\n",
      "Unique clusters (excluding -1): {np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6)}\n"
     ]
    }
   ],
   "source": [
    "  import numpy as np\n",
    "\n",
    "  data = np.load(\"X4_umap_hdbscan_outputs.npz\")\n",
    "\n",
    "  X4_umap_d = data[\"X4_umap_d\"]\n",
    "  X4_labels = data[\"X4_labels\"]\n",
    "\n",
    "  print(\"Loaded X4_umap_d shape:\", X4_umap_d.shape)\n",
    "  print(\"Loaded X4_labels shape:\", X4_labels.shape)\n",
    "  print(\"Unique clusters (excluding -1):\", set(X4_labels) - {-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb73eb7-646f-44ba-8203-fe3e629a6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide metric data into cat and num\n",
    "import re\n",
    "import pandas as pd\n",
    "metric_def = pd.read_excel(PATH_METRIC_DEF)\n",
    "\n",
    "metric_def[\"Metric_ID\"] = metric_def[\"Metric_ID\"].astype(str).str.strip()\n",
    "metric_def[\"Variable_type\"] = metric_def[\"Variable_type\"].astype(str).str.strip().str.lower()\n",
    "metric_def[\"Description\"] = metric_def[\"Description\"].astype(str).str.strip()\n",
    "\n",
    "type_by_id = dict(zip(metric_def[\"Metric_ID\"], metric_def[\"Variable_type\"]))\n",
    "desc_by_id = dict(zip(metric_def[\"Metric_ID\"], metric_def[\"Description\"]))\n",
    "\n",
    "num_cols = []\n",
    "cat_cols = []\n",
    "rename_map = {}\n",
    "\n",
    "for col in X2.columns:\n",
    "    m = re.search(r\"mtrc(\\d+)\", col, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    metric_id = m.group(1)\n",
    "    var_type = type_by_id.get(metric_id, \"\")\n",
    "\n",
    "    desc = desc_by_id.get(metric_id, \"\")\n",
    "    new_col = f\"{col}:{desc}\" if desc else col\n",
    "    rename_map[col] = new_col\n",
    "\n",
    "    if var_type == \"numeric\":\n",
    "        num_cols.append(new_col)\n",
    "    elif var_type in {\"binary\", \"count\"}:\n",
    "        cat_cols.append(new_col)\n",
    "\n",
    "X2 = X2.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ee4568-b409-4464-b2e9-acf81c680396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: iai_import_cell.py  (run in notebook with: %run iai_import_cell.py)\n"
     ]
    }
   ],
   "source": [
    "  cell = \"\"\"import os\n",
    "  from pathlib import Path\n",
    "\n",
    "  # Clean env that can break PyCall\n",
    "  os.environ.pop(\"PYTHONHOME\", None)\n",
    "  os.environ.pop(\"PYTHONPATH\", None)\n",
    "\n",
    "  # Tell interpretableai where Julia + sysimage are\n",
    "  os.environ[\"IAI_JULIA\"] = \"/Users/jingyi/Library/Application Support/InterpretableAI/julia/1.12.2/julia-1.12.2/bin/julia\"\n",
    "  os.environ[\"IAI_SYSTEM_IMAGE\"] = \"/Users/jingyi/Library/Application Support/InterpretableAI/sysimage/v3.2.2/sys.dylib\"\n",
    "\n",
    "  # Important: let IAI start Julia, but disable compiled modules\n",
    "  os.environ[\"IAI_DISABLE_COMPILED_MODULES\"] = \"1\"\n",
    "\n",
    "  # License\n",
    "  os.environ[\"IAI_LICENSE_FILE\"] = \"/Users/jingyi/Desktop/Trauma_LLM/iai.lic\"\n",
    "\n",
    "  # Now import\n",
    "  from interpretableai import iai\n",
    "  print(\"IAI import OK\")\n",
    "  \"\"\"\n",
    "  from pathlib import Path\n",
    "  Path(\"iai_import_cell.py\").write_text(cell)\n",
    "  print(\"Saved: iai_import_cell.py  (run in notebook with: %run iai_import_cell.py)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16dc878-5852-4fd7-bcd3-bca5b34e8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Imported binding MainInclude.eval was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.eval into Main conflicts with an existing identifier; ignored.\n",
      "WARNING: Imported binding MainInclude.include was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.include into Main conflicts with an existing identifier; ignored.\n",
      "WARNING: Imported binding MainInclude.eval was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.eval into Main conflicts with an existing identifier; ignored.\n",
      "WARNING: Imported binding MainInclude.include was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.include into Main conflicts with an existing identifier; ignored.\n",
      "WARNING:root:This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAI import OK\n"
     ]
    }
   ],
   "source": [
    "%run iai_import_cell.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d99c65d-12be-4c12-ac67-9ec6576b4add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_key</th>\n",
       "      <th>mtrc3:Time to first medical contact, min</th>\n",
       "      <th>mtrc4:Prehospital time, min</th>\n",
       "      <th>mtrc46:ICU length of stay, day</th>\n",
       "      <th>mtrc47:Length of stay, day</th>\n",
       "      <th>mtrc17:Time to cranial CT for patients with GCS &lt; 14, min</th>\n",
       "      <th>mtrc28:Time to first emergent surgery, min</th>\n",
       "      <th>mtrc31:Time to surgery for patients in shock, min</th>\n",
       "      <th>mtrc172:Time to tracheostomy in SCI patients, min</th>\n",
       "      <th>mtrc255:Time to tracheostomy, min</th>\n",
       "      <th>...</th>\n",
       "      <th>mtrc71:MRI - 2 hours</th>\n",
       "      <th>mtrc250:EVD placement</th>\n",
       "      <th>mtrc16:Antibiotics for open fractures</th>\n",
       "      <th>mtrc16001:Antibiotics for open fractures within 24 hours</th>\n",
       "      <th>mtrc23:Activation of massive transfusion protovocl</th>\n",
       "      <th>mtrc67:Convential radiology - in 15 min, level I/II; in 30 min, level III/IV</th>\n",
       "      <th>mtrc68:CT - in 15 min, level I/II; in 30 min, level III/IV</th>\n",
       "      <th>mtrc177:Percentage of severe TBI with other injury</th>\n",
       "      <th>mtrc187:Transfer rate of children with severe TBI</th>\n",
       "      <th>mtrc65:Orthopedic non-emergent availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>116</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>117</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inc_key  mtrc3:Time to first medical contact, min  \\\n",
       "0        1                                       NaN   \n",
       "1        2                                       7.0   \n",
       "2      111                                      11.0   \n",
       "3      112                                      11.0   \n",
       "4      113                                      11.0   \n",
       "5      114                                       NaN   \n",
       "6      115                                       NaN   \n",
       "7      116                                      13.0   \n",
       "8      117                                       7.0   \n",
       "9      118                                       NaN   \n",
       "\n",
       "   mtrc4:Prehospital time, min  mtrc46:ICU length of stay, day  \\\n",
       "0                          NaN                             2.0   \n",
       "1                          NaN                             NaN   \n",
       "2                          NaN                             NaN   \n",
       "3                          NaN                             NaN   \n",
       "4                          NaN                             3.0   \n",
       "5                          NaN                             NaN   \n",
       "6                          NaN                             2.0   \n",
       "7                          NaN                             NaN   \n",
       "8                          NaN                             1.0   \n",
       "9                          NaN                             2.0   \n",
       "\n",
       "   mtrc47:Length of stay, day  \\\n",
       "0                         4.0   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         4.0   \n",
       "5                         NaN   \n",
       "6                         2.0   \n",
       "7                         NaN   \n",
       "8                         5.0   \n",
       "9                         2.0   \n",
       "\n",
       "   mtrc17:Time to cranial CT for patients with GCS < 14, min  \\\n",
       "0                                                NaN           \n",
       "1                                                NaN           \n",
       "2                                                NaN           \n",
       "3                                                NaN           \n",
       "4                                                NaN           \n",
       "5                                                NaN           \n",
       "6                                                NaN           \n",
       "7                                                NaN           \n",
       "8                                                NaN           \n",
       "9                                                NaN           \n",
       "\n",
       "   mtrc28:Time to first emergent surgery, min  \\\n",
       "0                                         4.0   \n",
       "1                                        44.0   \n",
       "2                                       107.0   \n",
       "3                                        81.0   \n",
       "4                                        26.0   \n",
       "5                                         NaN   \n",
       "6                                       188.0   \n",
       "7                                       133.0   \n",
       "8                                        28.0   \n",
       "9                                        74.0   \n",
       "\n",
       "   mtrc31:Time to surgery for patients in shock, min  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                               28.0   \n",
       "9                                               74.0   \n",
       "\n",
       "   mtrc172:Time to tracheostomy in SCI patients, min  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "   mtrc255:Time to tracheostomy, min  ...  mtrc71:MRI - 2 hours  \\\n",
       "0                                NaN  ...                   NaN   \n",
       "1                                NaN  ...                   NaN   \n",
       "2                                NaN  ...                   NaN   \n",
       "3                                NaN  ...                   NaN   \n",
       "4                                NaN  ...                   NaN   \n",
       "5                                NaN  ...                   NaN   \n",
       "6                                NaN  ...                   NaN   \n",
       "7                                NaN  ...                   NaN   \n",
       "8                                NaN  ...                   NaN   \n",
       "9                                NaN  ...                   NaN   \n",
       "\n",
       "   mtrc250:EVD placement  mtrc16:Antibiotics for open fractures  \\\n",
       "0                    NaN                                    NaN   \n",
       "1                    0.0                                    NaN   \n",
       "2                    NaN                                    NaN   \n",
       "3                    NaN                                    NaN   \n",
       "4                    NaN                                    NaN   \n",
       "5                    NaN                                    NaN   \n",
       "6                    0.0                                    NaN   \n",
       "7                    NaN                                    NaN   \n",
       "8                    0.0                                    NaN   \n",
       "9                    NaN                                    NaN   \n",
       "\n",
       "   mtrc16001:Antibiotics for open fractures within 24 hours  \\\n",
       "0                                                NaN          \n",
       "1                                                NaN          \n",
       "2                                                NaN          \n",
       "3                                                NaN          \n",
       "4                                                NaN          \n",
       "5                                                NaN          \n",
       "6                                                NaN          \n",
       "7                                                NaN          \n",
       "8                                                NaN          \n",
       "9                                                NaN          \n",
       "\n",
       "   mtrc23:Activation of massive transfusion protovocl  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "5                                                NaN    \n",
       "6                                                NaN    \n",
       "7                                                NaN    \n",
       "8                                                NaN    \n",
       "9                                                NaN    \n",
       "\n",
       "   mtrc67:Convential radiology - in 15 min, level I/II; in 30 min, level III/IV  \\\n",
       "0                                                0.0                              \n",
       "1                                                0.0                              \n",
       "2                                                NaN                              \n",
       "3                                                NaN                              \n",
       "4                                                NaN                              \n",
       "5                                                NaN                              \n",
       "6                                                NaN                              \n",
       "7                                                NaN                              \n",
       "8                                                NaN                              \n",
       "9                                                NaN                              \n",
       "\n",
       "   mtrc68:CT - in 15 min, level I/II; in 30 min, level III/IV  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                NaN            \n",
       "3                                                NaN            \n",
       "4                                                NaN            \n",
       "5                                                NaN            \n",
       "6                                                NaN            \n",
       "7                                                NaN            \n",
       "8                                                NaN            \n",
       "9                                                NaN            \n",
       "\n",
       "   mtrc177:Percentage of severe TBI with other injury  \\\n",
       "0                                                  0    \n",
       "1                                                  1    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "5                                                  0    \n",
       "6                                                  1    \n",
       "7                                                  0    \n",
       "8                                                  1    \n",
       "9                                                  0    \n",
       "\n",
       "   mtrc187:Transfer rate of children with severe TBI  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "   mtrc65:Orthopedic non-emergent availability  \n",
       "0                                            0  \n",
       "1                                            0  \n",
       "2                                            0  \n",
       "3                                            0  \n",
       "4                                            0  \n",
       "5                                            0  \n",
       "6                                            0  \n",
       "7                                            0  \n",
       "8                                            0  \n",
       "9                                            0  \n",
       "\n",
       "[10 rows x 116 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  # check the work\n",
    "  # show first 10 rows\n",
    "  display(X2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43f9549b-145a-4056-8d3c-f2e89c8b2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) Inputs + missing tokens\n",
    "# =========================\n",
    "MISSING_TOKENS = {\n",
    "    \"\", \" \", \"  \", \"\\t\", \"\\n\", \"\\r\",\n",
    "    \"na\", \"n/a\", \"nan\", \"null\", \"none\", \"nil\",\n",
    "    \".\", \"..\", \"...\",\n",
    "    \"<unk>\", \"unk\", \"unknown\", \"missing\", \"nan\", \"na\"\n",
    "}\n",
    "\n",
    "df_X1 = X1\n",
    "df_X2 = X2\n",
    "df_X4 = X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70d535-dcbf-454b-82da-3f604cce6bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aff0ff9-eb05-481f-95de-70a08d4273ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Preprocess X2 (outside function)\n",
    "# =========================\n",
    "X = df_X2.drop(columns=[\"inc_key\"], errors=\"ignore\").copy()\n",
    "\n",
    "cat_cols = [c for c in cat_cols if c in X.columns]\n",
    "num_cols = [c for c in num_cols if c in X.columns]\n",
    "\n",
    "for col in cat_cols + num_cols:\n",
    "    s = X[col]\n",
    "    s_str = s.astype(str).str.strip().str.lower()\n",
    "    miss = s.isna() | s_str.isin(MISSING_TOKENS)\n",
    "\n",
    "    if col in cat_cols:\n",
    "        X.loc[miss, col] = \"MISSING\"\n",
    "        X[col] = X[col].astype(str)\n",
    "    else:\n",
    "        X[col] = pd.to_numeric(s, errors=\"coerce\")\n",
    "        miss2 = miss | X[col].isna()\n",
    "        X.loc[miss2, col] = 0\n",
    "\n",
    "# fix feature types\n",
    "overlap = set(cat_cols) & set(num_cols)\n",
    "if overlap:\n",
    "    print(\"Removing from num_cols (categorical):\", overlap)\n",
    "    num_cols = [c for c in num_cols if c not in overlap]\n",
    "\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "\n",
    "for c in num_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a75def5-3d33-4c30-b8b9-c0044d88149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Align by inc_key (outside)\n",
    "# =========================\n",
    "df1 = df_X1[[\"inc_key\"]].copy()\n",
    "df1[\"x1_cluster\"] = np.asarray(X1_labels).astype(int)\n",
    "\n",
    "df4 = df_X4[[\"inc_key\"]].copy()\n",
    "df4[\"x4_cluster\"] = np.asarray(X4_labels).astype(int)\n",
    "\n",
    "if df1[\"inc_key\"].duplicated().any():\n",
    "    raise ValueError(\"df_X1 has duplicated inc_key. Deduplicate first.\")\n",
    "if df4[\"inc_key\"].duplicated().any():\n",
    "    raise ValueError(\"df_X4 has duplicated inc_key. Deduplicate first.\")\n",
    "if df_X2[\"inc_key\"].duplicated().any():\n",
    "    raise ValueError(\"df_X2 has duplicated inc_key. Deduplicate first.\")\n",
    "\n",
    "X_with_key = df_X2[[\"inc_key\"]].copy()\n",
    "X_with_key = X_with_key.join(X)\n",
    "\n",
    "aligned = df1.merge(X_with_key, on=\"inc_key\", how=\"inner\").merge(df4, on=\"inc_key\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66aa9323-b235-4546-8196-69ab80cc2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) IAI per X1 cluster → predict X4\n",
    "# =========================\n",
    "def run_iai_per_x1_cluster(\n",
    "    aligned_df: pd.DataFrame,\n",
    "    cat_cols: list[str],\n",
    "    num_cols: list[str],\n",
    "    output_dir: str = \"./iai_trees\",\n",
    "    include_noise: bool = False,\n",
    "    min_class_count: int = 2,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "    max_depth: int = 5,\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    df = aligned_df.copy()\n",
    "    if not include_noise:\n",
    "        df = df[(df[\"x1_cluster\"] != -1) & (df[\"x4_cluster\"] != -1)].copy()\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"inc_key\", \"x1_cluster\", \"x4_cluster\"]]\n",
    "    used_cols = [c for c in feature_cols if c in (cat_cols + num_cols)]\n",
    "\n",
    "    clusters = sorted(df[\"x1_cluster\"].unique().tolist())\n",
    "    results = []\n",
    "\n",
    "    for c in clusters:\n",
    "        sub = df[df[\"x1_cluster\"] == c].copy()\n",
    "        y = sub[\"x4_cluster\"].astype(int)\n",
    "\n",
    "        if y.nunique() < 2:\n",
    "            results.append((c, len(sub), y.nunique(), \"SKIP (no split)\"))\n",
    "            continue\n",
    "\n",
    "        vc = y.value_counts()\n",
    "        keep = vc[vc >= min_class_count].index\n",
    "        sub = sub[y.isin(keep)].copy()\n",
    "        y = sub[\"x4_cluster\"].astype(int)\n",
    "\n",
    "        if y.nunique() < 2:\n",
    "            results.append((c, len(sub), y.nunique(), f\"SKIP (after filtering <{min_class_count})\"))\n",
    "            continue\n",
    "\n",
    "        X_sub = sub[used_cols]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_sub, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        grid = iai.GridSearch(iai.OptimalTreeClassifier(random_seed=1),max_depth=5,)\n",
    "        grid.fit(X_train, y_train)\n",
    "        learner = grid.get_learner()\n",
    "\n",
    "        test_acc = learner.score(X_test, y_test)\n",
    "\n",
    "        model_path = os.path.join(output_dir, f\"iai_x1cluster_{c}_depth{max_depth}.json\")\n",
    "        learner.write_json(model_path)\n",
    "\n",
    "        results.append((c, len(sub), y.nunique(), f\"OK → acc={test_acc:.4f} | {model_path}\"))\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"x1_cluster\", \"n_samples_used\", \"num_x4_classes\", \"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aacf503c-1762-43f8-90dc-48df4ec42952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe following categoric features have more than 10 levels:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- mtrc81:Craniofacial expertise\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mWe recommend extreme caution when using categoric features with many levels inside Optimal Trees, for more information and advice on how to handle such features, please refer to this link:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mhttps://docs.interpretable.ai/dev/OptimalTrees/tips/#Categorical-Variables-with-Many-Levels\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mYou can suppress this warning by increasing the value of the parameter `max_categoric_levels_before_warning` on the Optimal Tree learner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1_cluster  n_samples_used  num_x4_classes  \\\n",
      "0           0           21683               4   \n",
      "1           1            4505               2   \n",
      "2           2            2450               1   \n",
      "3           3             809               2   \n",
      "4           4            8297               3   \n",
      "5           5           27681               4   \n",
      "6           6            4432               4   \n",
      "7           7           33502               5   \n",
      "\n",
      "                                              status  \n",
      "0  OK → acc=0.6313 | ./iai_trees_depth5/iai_x1clu...  \n",
      "1  OK → acc=0.6837 | ./iai_trees_depth5/iai_x1clu...  \n",
      "2                                    SKIP (no split)  \n",
      "3  OK → acc=0.9877 | ./iai_trees_depth5/iai_x1clu...  \n",
      "4  OK → acc=0.8928 | ./iai_trees_depth5/iai_x1clu...  \n",
      "5  OK → acc=0.7226 | ./iai_trees_depth5/iai_x1clu...  \n",
      "6  OK → acc=0.7971 | ./iai_trees_depth5/iai_x1clu...  \n",
      "7  OK → acc=0.7297 | ./iai_trees_depth5/iai_x1clu...  \n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4) Run\n",
    "# =========================\n",
    "summary = run_iai_per_x1_cluster(\n",
    "    aligned_df=aligned,\n",
    "    cat_cols=cat_cols,\n",
    "    num_cols=num_cols,\n",
    "    output_dir=\"./iai_trees_depth5\",\n",
    "    include_noise=False,\n",
    "    min_class_count=2,\n",
    "    max_depth=5,\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a43f661a-8041-42d5-850f-39009bf58209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ./iai_trees_depth5/iai_x1cluster_4_depth5.html\n",
      "Wrote: ./iai_trees_depth5/iai_x1cluster_1_depth5.html\n",
      "Wrote: ./iai_trees_depth5/iai_x1cluster_7_depth5.html\n",
      "Wrote: ./iai_trees_depth5/iai_x1cluster_0_depth5.html\n",
      "Wrote: ./iai_trees_depth5/iai_x1cluster_5_depth5.html\n",
      "Wrote: ./iai_trees_depth5/iai_x1cluster_6_depth5.html\n",
      "Wrote: ./iai_trees_depth5/iai_x1cluster_3_depth5.html\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from interpretableai.iaibase import read_json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "model_dir = \"./iai_trees_depth5\"\n",
    "\n",
    "for json_path in glob.glob(os.path.join(model_dir, \"iai_x1cluster_*_depth5.json\")):\n",
    "    learner = read_json(json_path)\n",
    "    html_path = json_path.replace(\".json\", \".html\")\n",
    "    learner.write_html(html_path)\n",
    "    print(\"Wrote:\", html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff6294fa-2732-452a-8f85-d3d4dc20581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_4_depth5.json ===\n",
      "X1 cluster 4 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_1_depth5.json ===\n",
      "X1 cluster 1 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_7_depth5.json ===\n",
      "X1 cluster 7 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_0_depth5.json ===\n",
      "X1 cluster 0 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_5_depth5.json ===\n",
      "X1 cluster 5 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_6_depth5.json ===\n",
      "X1 cluster 6 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_3_depth5.json ===\n",
      "X1 cluster 3 patient -> when (all), then predict None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "# --------- helpers to read JSON ----------\n",
    "def load_json(path: str) -> Dict[str, Any]:\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def first_key(d: Dict[str, Any], keys: List[str]) -> Optional[Any]:\n",
    "    for k in keys:\n",
    "        if k in d:\n",
    "            return d[k]\n",
    "    return None\n",
    "\n",
    "\n",
    "# --------- tree structure handling ----------\n",
    "def get_tree_root(data: Dict[str, Any]):\n",
    "    # Try common layouts\n",
    "    for key in [\"tree\", \"model\", \"learner\", \"root\"]:\n",
    "        if key in data:\n",
    "            data = data[key]\n",
    "            break\n",
    "\n",
    "    # Flat node list with root id\n",
    "    if isinstance(data, dict) and \"nodes\" in data:\n",
    "        nodes = data[\"nodes\"]\n",
    "        node_map = {}\n",
    "        for i, n in enumerate(nodes):\n",
    "            node_id = n.get(\"id\", i)\n",
    "            node_map[node_id] = n\n",
    "        root_id = data.get(\"root\", data.get(\"root_id\", 0))\n",
    "        if isinstance(root_id, dict):\n",
    "            return root_id\n",
    "        return node_map[root_id]\n",
    "\n",
    "    # If already hierarchical\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_children(node: Dict[str, Any]) -> Tuple[Optional[Dict], Optional[Dict]]:\n",
    "    # Common child keys\n",
    "    for lk, rk in [\n",
    "        (\"left\", \"right\"),\n",
    "        (\"left_child\", \"right_child\"),\n",
    "        (\"leftChild\", \"rightChild\"),\n",
    "        (\"l\", \"r\"),\n",
    "    ]:\n",
    "        if lk in node and rk in node:\n",
    "            return node[lk], node[rk]\n",
    "\n",
    "    # Sometimes children are indices and stored in \"nodes\"\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def is_leaf(node: Dict[str, Any]) -> bool:\n",
    "    if node is None:\n",
    "        return True\n",
    "    if \"prediction\" in node or \"predicted_class\" in node or \"class\" in node:\n",
    "        return True\n",
    "    left, right = get_children(node)\n",
    "    return left is None and right is None\n",
    "\n",
    "\n",
    "def get_prediction(node: Dict[str, Any]):\n",
    "    for k in [\"prediction\", \"predicted_class\", \"class\", \"value\"]:\n",
    "        if k in node:\n",
    "            return node[k]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_prob(node: Dict[str, Any]):\n",
    "    for k in [\"prob\", \"probability\", \"p\", \"class_probability\", \"class_probabilities\"]:\n",
    "        if k in node:\n",
    "            return node[k]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_split(node: Dict[str, Any]):\n",
    "    feature = first_key(node, [\"feature\", \"split_feature\", \"feature_name\", \"var\"])\n",
    "    threshold = first_key(node, [\"threshold\", \"split_value\", \"value\"])\n",
    "    operator = first_key(node, [\"operator\", \"op\", \"comparison\"])\n",
    "    categories = first_key(node, [\"categories\", \"cat_values\", \"values\"])\n",
    "    missing_left = first_key(node, [\"missing_to_left\", \"default_left\", \"missing_left\"])\n",
    "    return feature, threshold, operator, categories, missing_left\n",
    "\n",
    "\n",
    "def build_conditions(node: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    feature, threshold, operator, categories, missing_left = get_split(node)\n",
    "\n",
    "    if feature is None:\n",
    "        return \"UNKNOWN_SPLIT\", \"UNKNOWN_SPLIT\"\n",
    "\n",
    "    # Categorical split\n",
    "    if categories is not None:\n",
    "        cats = categories if isinstance(categories, list) else [categories]\n",
    "        left_cond = f\"{feature} in {cats}\"\n",
    "        right_cond = f\"{feature} not in {cats}\"\n",
    "    else:\n",
    "        # Numeric split\n",
    "        if operator is None:\n",
    "            operator = \"<=\"\n",
    "        if threshold is None:\n",
    "            threshold = \"?\"\n",
    "        left_cond = f\"{feature} {operator} {threshold}\"\n",
    "        right_cond = f\"{feature} not({operator} {threshold})\"\n",
    "\n",
    "    if missing_left is True:\n",
    "        left_cond = f\"{left_cond} or missing\"\n",
    "    elif missing_left is False:\n",
    "        right_cond = f\"{right_cond} or missing\"\n",
    "\n",
    "    return left_cond, right_cond\n",
    "\n",
    "\n",
    "def walk_paths(node: Dict[str, Any], conditions: List[str]):\n",
    "    if node is None:\n",
    "        return []\n",
    "\n",
    "    if is_leaf(node):\n",
    "        pred = get_prediction(node)\n",
    "        prob = get_prob(node)\n",
    "        return [(conditions, pred, prob)]\n",
    "\n",
    "    left, right = get_children(node)\n",
    "    left_cond, right_cond = build_conditions(node)\n",
    "\n",
    "    paths = []\n",
    "    if left is not None:\n",
    "        paths += walk_paths(left, conditions + [left_cond])\n",
    "    if right is not None:\n",
    "        paths += walk_paths(right, conditions + [right_cond])\n",
    "    return paths\n",
    "\n",
    "\n",
    "def format_path(cluster_id: str, conds: List[str], pred, prob) -> str:\n",
    "    cond_text = \" and \".join(conds) if conds else \"(all)\"\n",
    "    if isinstance(prob, dict):\n",
    "        # if class prob dict, show max\n",
    "        max_class = max(prob, key=prob.get)\n",
    "        max_p = prob[max_class]\n",
    "        prob_text = f\" (p={max_p:.1%})\"\n",
    "    elif isinstance(prob, (float, int)):\n",
    "        prob_text = f\" (p={prob:.1%})\"\n",
    "    else:\n",
    "        prob_text = \"\"\n",
    "    return f\"X1 cluster {cluster_id} patient -> when {cond_text}, then predict {pred}{prob_text}\"\n",
    "\n",
    "\n",
    "# --------- main: load all jsons and print paths ----------\n",
    "model_dir = \"./iai_trees_depth5\"\n",
    "\n",
    "for json_path in glob.glob(os.path.join(model_dir, \"iai_x1cluster_*_depth5.json\")):\n",
    "    data = load_json(json_path)\n",
    "    root = get_tree_root(data)\n",
    "\n",
    "    cluster_match = re.search(r\"x1cluster_(\\d+)_depth\", os.path.basename(json_path))\n",
    "    cluster_id = cluster_match.group(1) if cluster_match else \"?\"\n",
    "\n",
    "    paths = walk_paths(root, [])\n",
    "    print(f\"\\n=== {json_path} ===\")\n",
    "    if not paths:\n",
    "        print(\"No paths found. Top-level keys:\", list(data.keys()))\n",
    "        continue\n",
    "    for conds, pred, prob in paths:\n",
    "        print(format_path(cluster_id, conds, pred, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2ee9447-5bda-4181-b171-fecc3307f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['max_depth', 'minbucket', 'weighted_minbucket', 'cp', 'cp_tuning_se_tolerance', 'localsearch', 'max_categoric_levels_before_warning', 'ls_num_tree_restarts', 'ls_num_hyper_restarts', 'ls_num_categoric_restarts', 'ls_num_greedy_features', 'ls_bootstrap_samples', 'ls_ignore_errors', 'ls_warmstart_criterion', 'ls_max_search_iterations', 'ls_max_hyper_iterations', 'ls_scan_reverse_split', 'fast_num_support_iterations', 'fast_num_support_restarts', 'fast_cumulative_support', 'fast_test_intermediate_support', 'missingdatamode', 'split_features', 'hyperplane_config', 'refit_learner', 'checkpoint_interval', 'tree_', 'all_trees_', 'regression_features', 'normalize_X', 'criterion', 'treat_unknown_level_missing', 'random_seed', 'parallel_processes', 'num_threads', 'show_progress', 'prb_', 'cpu_time_', 'checkpoint_file', 'checkpoint_dir', 'checkpoint_max_files', '_julia_type']\n",
      "split_features keys: ['All']\n",
      "hyperplane_config list length: 0\n",
      "tree_ keys: ['node_count', 'nodes', 'capacity']\n",
      "all_trees_ list length: 100\n",
      "regression_features list length: 0\n",
      "prb_ keys: ['data', 'baseline']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "path = \"./iai_trees_depth5/iai_x1cluster_4_depth5.json\"\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Top-level keys:\", list(data.keys()))\n",
    "\n",
    "# show 1 level down for any dict values\n",
    "for k, v in data.items():\n",
    "    if isinstance(v, dict):\n",
    "        print(f\"{k} keys:\", list(v.keys()))\n",
    "    elif isinstance(v, list):\n",
    "        print(f\"{k} list length:\", len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba15e28f-2c6d-4d71-a36f-df87c947f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_4_depth5.json ===\n",
      "X1 cluster 4 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_1_depth5.json ===\n",
      "X1 cluster 1 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_7_depth5.json ===\n",
      "X1 cluster 7 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_0_depth5.json ===\n",
      "X1 cluster 0 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_5_depth5.json ===\n",
      "X1 cluster 5 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_6_depth5.json ===\n",
      "X1 cluster 6 patient -> when (all), then predict None\n",
      "\n",
      "=== ./iai_trees_depth5/iai_x1cluster_3_depth5.json ===\n",
      "X1 cluster 3 patient -> when (all), then predict None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "def node_get(node: Dict[str, Any], keys: List[str], default=None):\n",
    "    for k in keys:\n",
    "        if k in node:\n",
    "            return node[k]\n",
    "    return default\n",
    "\n",
    "\n",
    "def build_feature_names(data: Dict[str, Any]) -> List[str]:\n",
    "    feats = data.get(\"split_features\", {}).get(\"All\", [])\n",
    "    return feats if isinstance(feats, list) else []\n",
    "\n",
    "\n",
    "def get_nodes(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    tree = data.get(\"tree_\", {})\n",
    "    nodes = tree.get(\"nodes\", [])\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def get_root_idx(nodes: List[Dict[str, Any]]) -> int:\n",
    "    # Try to find a root by parent == -1 / None\n",
    "    for i, n in enumerate(nodes):\n",
    "        parent = node_get(n, [\"parent\", \"parent_id\"], None)\n",
    "        if parent in (-1, None):\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_children(node: Dict[str, Any]) -> Tuple[Optional[int], Optional[int]]:\n",
    "    # Common child index keys\n",
    "    left = node_get(node, [\"left\", \"left_child\", \"left_child_id\", \"l\"], None)\n",
    "    right = node_get(node, [\"right\", \"right_child\", \"right_child_id\", \"r\"], None)\n",
    "\n",
    "    # Some schemas use \"children\": [l, r]\n",
    "    if left is None and right is None and \"children\" in node:\n",
    "        children = node[\"children\"]\n",
    "        if isinstance(children, list) and len(children) >= 2:\n",
    "            left, right = children[0], children[1]\n",
    "\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def is_leaf(node: Dict[str, Any]) -> bool:\n",
    "    if node_get(node, [\"is_leaf\", \"leaf\"], False):\n",
    "        return True\n",
    "    left, right = get_children(node)\n",
    "    return left is None and right is None\n",
    "\n",
    "\n",
    "def get_prediction(node: Dict[str, Any]):\n",
    "    return node_get(node, [\"prediction\", \"predicted_class\", \"class\", \"value\"], None)\n",
    "\n",
    "\n",
    "def get_prob(node: Dict[str, Any]):\n",
    "    # may be a list or dict\n",
    "    prob = node_get(node, [\"prob\", \"probability\", \"class_probabilities\", \"probs\"], None)\n",
    "    return prob\n",
    "\n",
    "\n",
    "def split_condition(node: Dict[str, Any], feature_names: List[str]) -> Tuple[str, str]:\n",
    "    feat_idx = node_get(node, [\"feature\", \"split_feature\", \"feature_index\"], None)\n",
    "    feat_name = None\n",
    "    if isinstance(feat_idx, int) and 0 <= feat_idx < len(feature_names):\n",
    "        feat_name = feature_names[feat_idx]\n",
    "    elif isinstance(feat_idx, str):\n",
    "        feat_name = feat_idx\n",
    "    else:\n",
    "        feat_name = \"UNKNOWN_FEATURE\"\n",
    "\n",
    "    threshold = node_get(node, [\"threshold\", \"split_value\", \"value\"], None)\n",
    "    operator = node_get(node, [\"operator\", \"op\", \"comparison\"], \"<=\")\n",
    "    categories = node_get(node, [\"categories\", \"cat_values\", \"values\"], None)\n",
    "    missing_left = node_get(node, [\"missing_to_left\", \"default_left\", \"missing_left\"], None)\n",
    "\n",
    "    if categories is not None:\n",
    "        cats = categories if isinstance(categories, list) else [categories]\n",
    "        left_cond = f\"{feat_name} in {cats}\"\n",
    "        right_cond = f\"{feat_name} not in {cats}\"\n",
    "    else:\n",
    "        left_cond = f\"{feat_name} {operator} {threshold}\"\n",
    "        right_cond = f\"{feat_name} not({operator} {threshold})\"\n",
    "\n",
    "    if missing_left is True:\n",
    "        left_cond += \" or missing\"\n",
    "    elif missing_left is False:\n",
    "        right_cond += \" or missing\"\n",
    "\n",
    "    return left_cond, right_cond\n",
    "\n",
    "\n",
    "def walk_paths(nodes: List[Dict[str, Any]], idx: int, feature_names: List[str], conds: List[str]):\n",
    "    node = nodes[idx]\n",
    "    if is_leaf(node):\n",
    "        return [(conds, get_prediction(node), get_prob(node))]\n",
    "\n",
    "    left, right = get_children(node)\n",
    "    left_cond, right_cond = split_condition(node, feature_names)\n",
    "\n",
    "    paths = []\n",
    "    if left is not None:\n",
    "        paths += walk_paths(nodes, left, feature_names, conds + [left_cond])\n",
    "    if right is not None:\n",
    "        paths += walk_paths(nodes, right, feature_names, conds + [right_cond])\n",
    "    return paths\n",
    "\n",
    "\n",
    "def format_path(cluster_id: str, conds: List[str], pred, prob) -> str:\n",
    "    cond_text = \" and \".join(conds) if conds else \"(all)\"\n",
    "    prob_text = \"\"\n",
    "    if isinstance(prob, dict):\n",
    "        max_class = max(prob, key=prob.get)\n",
    "        prob_text = f\" (p={prob[max_class]:.1%})\"\n",
    "    elif isinstance(prob, (list, tuple)) and len(prob) > 0:\n",
    "        max_p = max(prob)\n",
    "        prob_text = f\" (p={max_p:.1%})\"\n",
    "    elif isinstance(prob, (float, int)):\n",
    "        prob_text = f\" (p={prob:.1%})\"\n",
    "    return f\"X1 cluster {cluster_id} patient -> when {cond_text}, then predict {pred}{prob_text}\"\n",
    "\n",
    "\n",
    "model_dir = \"./iai_trees_depth5\"\n",
    "\n",
    "for json_path in glob.glob(os.path.join(model_dir, \"iai_x1cluster_*_depth5.json\")):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    feature_names = build_feature_names(data)\n",
    "    nodes = get_nodes(data)\n",
    "    if not nodes:\n",
    "        print(f\"\\n=== {json_path} ===\")\n",
    "        print(\"No nodes found.\")\n",
    "        continue\n",
    "\n",
    "    root_idx = get_root_idx(nodes)\n",
    "    cluster_match = re.search(r\"x1cluster_(\\d+)_depth\", os.path.basename(json_path))\n",
    "    cluster_id = cluster_match.group(1) if cluster_match else \"?\"\n",
    "\n",
    "    paths = walk_paths(nodes, root_idx, feature_names, [])\n",
    "    print(f\"\\n=== {json_path} ===\")\n",
    "    for conds, pred, prob in paths:\n",
    "        print(format_path(cluster_id, conds, pred, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14390c6d-1ce8-4d7f-a21d-6746a10f404a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwen venv)",
   "language": "python",
   "name": "qwen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
